{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, lets try a word embedding model. Hopefully this will be a bit more robust than the first model I played with, since the words are better represented than with a simple tokenizer. The basic model preformed adequately, so I'm not too concerned about it. I think applying GloVe embeddings will give the model the boost to be really powerful.\n",
    "\n",
    "Honestly my main concern is packaging the model for Heroku, since GloVe vectors are huge. I'm thinking I can train a model here, load it in a heroku app and then dockerize the entire thing.\n",
    "\n",
    "First lets import our Libraries and Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup a few helpers\n",
    "base_dir = ''\n",
    "glove_dir = os.path.join(base_dir, 'glove.6B')\n",
    "max_seq_len = 1000\n",
    "max_num_words = 20000\n",
    "embedding_dim = 100\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into pandas for easy handling\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "def encode_label_sum(integer):\n",
    "    if integer > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to binary label indicating toxicity, this will give us a simpler model in the end\n",
    "data['any_toxic'] = data[list_classes]\\\n",
    ".sum(axis = 1)\\\n",
    ".apply(encode_label_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>any_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
       "0             0        0       0       0              0          0  \n",
       "1             0        0       0       0              0          0  \n",
       "2             0        0       0       0              0          0  \n",
       "3             0        0       0       0              0          0  \n",
       "4             0        0       0       0              0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               False\n",
       "comment_text     False\n",
       "toxic            False\n",
       "severe_toxic     False\n",
       "obscene          False\n",
       "threat           False\n",
       "insult           False\n",
       "identity_hate    False\n",
       "any_toxic        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick sanity check\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see our dataset is adequately clean (Kaggle sure is nice). ~~I've gone ahead and split the \"testing\" data into testing and training.~~ I'm going to finish preprocessing and then split the data so I don't have to do it twice. I want to test on a subset of the data so I can validate the model. Once I'm confident in it, I can submit predictions to Kaggle for out-of-sample validation. That said, this is a luxury I seldom have so I don't want to lean on it like a crutch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chop up the data into the pieces we want\n",
    "labels = data['any_toxic'].values\n",
    "comments = data[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean         67.273527\n",
       "std          99.230702\n",
       "min           1.000000\n",
       "25%          17.000000\n",
       "50%          36.000000\n",
       "75%          75.000000\n",
       "max        1411.000000\n",
       "Name: comment_text, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You know, lets see how long these comments are in general\n",
    "comments\\\n",
    ".apply(lambda x: len(x.split()))\\\n",
    ".describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a20d80ba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20d804a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#some of those comments are crazy long, so lets get a birds eye view. \n",
    "comments\\\n",
    ".apply(lambda x: len(x.split()))\\\n",
    ".hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the dataset looks pretty hunky-dory. Lets tokenize it and get some embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before we figure out embeddings, \n",
    "#I'm gonna adjust the arbitrarily selected sequence length paramaters to fit this dataset.\n",
    "max_seq_len = 200 \n",
    "#lets cut this down to 200 for shorter input tensors and less empty space,\n",
    "#we won't be loosing much of the dataset and it'll train quicker\n",
    "max_num_words = 20000\n",
    "embedding_dim = 100\n",
    "#vocab size and Embedding dims still seem okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the comments\n",
    "comment_tokenizer = Tokenizer(num_words=max_num_words)\n",
    "comment_tokenizer.fit_on_texts(list(comments))\n",
    "sequences = comment_tokenizer.texts_to_sequences(list(comments))\n",
    "\n",
    "comment_word_index = comment_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 210337 Words\n"
     ]
    }
   ],
   "source": [
    "print(f\"We got {len(comment_word_index)} Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (159571, 200)\n",
      "Shape of label tensor: (159571, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the shapes check out, trying to fit 159571 comments of 200 words in length into six binary categories.\n",
    "\n",
    "Now lets split off a validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test =\\\n",
    "train_test_split(data, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, all the preprocessing is complete. Lets start on embedding layers. First, gotta load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's 400000 embeddings.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(f'there\\'s {len(embeddings_index)} embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(comment_word_index) + 1, embedding_dim))\n",
    "for word, i in comment_word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.18970001,  0.050024  ,  0.19084001, ..., -0.39804   ,\n",
       "         0.47646999, -0.15983   ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.07574   ,  0.42109001,  0.77687001, ...,  0.095977  ,\n",
       "         1.62820005, -0.10819   ],\n",
       "       [ 0.068997  , -0.31268999, -0.24092001, ..., -0.06305   ,\n",
       "         0.52090001,  0.45936   ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(comment_word_index) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_seq_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our embedding layer to start out net. Lets put together a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_seq_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='relu')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/2\n",
      "  2176/127656 [..............................] - ETA: 4:59 - loss: nan - acc: 0.8644"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2a138ce330c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# happy learning!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(data_train, labels_train, validation_data=(data_test, labels_test),\n\u001b[0;32m----> 3\u001b[0;31m           epochs=2, batch_size=128)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# happy learning!\n",
    "model.fit(data_train, labels_train, validation_data=(data_test, labels_test),\n",
    "          epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
