{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just a scratch pad for working out a pipeline to turn user text into a prediction. Once I have the outline here I'm going to refactor it into a script or module for the webapp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-development/models/cat-cross-model-e2.h5')\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string_civil = '''What's this you've said to me, my good friend? \n",
    "I'll have you know I graduated top of my class in conflict resolution, \n",
    "and I've been involved in numerous friendly discussions, \n",
    "and I have over 300 confirmed friends. \n",
    "I am trained in polite discussions and I'm the top mediator in the entire neighbourhood. \n",
    "You are worth more to me than just another target. \n",
    "I hope we will come to have a friendship never before seen on this Earth. \n",
    "Don't you think you might be hurting someone's feelings saying that over the internet? \n",
    "Think about it, my friend. As we speak I am contacting my good friends across the USA and your P.O. box is being traced right now so you better prepare for the greeting cards, friend. \n",
    "The greeting cards that help you with your hate. \n",
    "You should look forward to it, friend. I can be anywhere, anytime for you, and I can calm you in over seven hundred ways, \n",
    "and that's just with my chess set. Not only am I extensively trained in conflict resolution, \n",
    "but I have access to the entire group of my friends and I will use them to their full extent to start our new friendship. \n",
    "If only you could have known what kindness and love your little comment was about to bring you, \n",
    "maybe you would have reached out sooner. But you couldn't, you didn't, and now we get to start a new friendship, \n",
    "you unique person. I will give you gifts and you might have a hard time keeping up. You're finally living, friend.'''\n",
    "\n",
    "test_string_toxic = '''What the fuck did you just fucking say about me, you little bitch? \n",
    "I’ll have you know I graduated top of my class in the Navy Seals, \n",
    "and I’ve been involved in numerous secret raids on Al-Quaeda, \n",
    "and I have over 300 confirmed kills. \n",
    "I am trained in gorilla warfare and I’m the top sniper in the entire US armed forces. \n",
    "You are nothing to me but just another target. \n",
    "I will wipe you the fuck out with precision the likes of which has never been seen before on this Earth, mark my fucking words. \n",
    "You think you can get away with saying that shit to me over the Internet? \n",
    "Think again, fucker. As we speak I am contacting my secret network of spies across the USA and your IP is being traced right now so you better prepare for the storm, maggot. \n",
    "The storm that wipes out the pathetic little thing you call your life. You’re fucking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, \n",
    "and that’s just with my bare hands. Not only am I extensively trained in unarmed combat, \n",
    "but I have access to the entire arsenal of the United States Marine Corps \n",
    "and I will use it to its full extent to wipe your miserable ass off the face of the continent, \n",
    "you little shit. If only you could have known what unholy retribution your little “clever” comment \n",
    "was about to bring down upon you, maybe you would have held your fucking tongue. \n",
    "But you couldn’t, you didn’t, and now you’re paying the price, you goddamn idiot. \n",
    "I will shit fury all over you and you will drown in it. You’re fucking dead, kiddo.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open('model-development/models/comment-tokenizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = tokenizer.texts_to_sequences([test_string_civil])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = pad_sequences(np.array(test_seq), maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_arr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98149121,  0.01850882], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_prob = prediction[1]\n",
    "civil_prob = prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this comment is more likely to be civil(0.981491208076477) than toxic(0.018508821725845337)\n"
     ]
    }
   ],
   "source": [
    "if toxic_prob > civil_prob:\n",
    "    print(f'this comment is more likely to be toxic({toxic_prob}) than civil({civil_prob})')\n",
    "else:\n",
    "    print(f'this comment is more likely to be civil({civil_prob}) than toxic({toxic_prob})')\n",
    "assert toxic_prob + civil_prob == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score_Comment(comment, model, tokenizer, expected_len):\n",
    "    tokens = tokenizer.texts_to_sequences([comment])\n",
    "    arr = pad_sequences(tokens, maxlen=expected_len)\n",
    "    pred = model.predict(arr)[0]\n",
    "    return pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99979335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Score_Comment(test_string_toxic, model=model, tokenizer=tokenizer, expected_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Report_Comment(comment, model, tokenizer, expected_len):\n",
    "    score = Score_Comment(comment, model, tokenizer, expected_len)\n",
    "    return f\"the string:\\n'''{comment}'''\\nHas a {score*100}% probability of being toxic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the string:\n",
      "'''What's this you've said to me, my good friend? \n",
      "I'll have you know I graduated top of my class in conflict resolution, \n",
      "and I've been involved in numerous friendly discussions, \n",
      "and I have over 300 confirmed friends. \n",
      "I am trained in polite discussions and I'm the top mediator in the entire neighbourhood. \n",
      "You are worth more to me than just another target. \n",
      "I hope we will come to have a friendship never before seen on this Earth. \n",
      "Don't you think you might be hurting someone's feelings saying that over the internet? \n",
      "Think about it, my friend. As we speak I am contacting my good friends across the USA and your P.O. box is being traced right now so you better prepare for the greeting cards, friend. \n",
      "The greeting cards that help you with your hate. \n",
      "You should look forward to it, friend. I can be anywhere, anytime for you, and I can calm you in over seven hundred ways, \n",
      "and that's just with my chess set. Not only am I extensively trained in conflict resolution, \n",
      "but I have access to the entire group of my friends and I will use them to their full extent to start our new friendship. \n",
      "If only you could have known what kindness and love your little comment was about to bring you, \n",
      "maybe you would have reached out sooner. But you couldn't, you didn't, and now we get to start a new friendship, \n",
      "you unique person. I will give you gifts and you might have a hard time keeping up. You're finally living, friend.'''\n",
      "Has a 1.8508821725845337% probability of being toxic\n"
     ]
    }
   ],
   "source": [
    "print(Report_Comment(test_string_civil, model=model, tokenizer=tokenizer, expected_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
